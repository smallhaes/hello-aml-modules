{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Run, Dataset, Datastore\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.pipeline.wrapper import Module, dsl\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n",
    "\n",
    "aml_compute_target = \"aml-compute\"\n",
    "try:\n",
    "    aml_compute = AmlCompute(ws, aml_compute_target)\n",
    "    print(\"Found existing compute target: {}\".format(aml_compute_target))\n",
    "except:\n",
    "    print(\"Creating new compute target: {}\".format(aml_compute_target))\n",
    "    \n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\",\n",
    "                                                                min_nodes = 1, \n",
    "                                                                max_nodes = 4)    \n",
    "    aml_compute = ComputeTarget.create(ws, aml_compute_target, provisioning_config)\n",
    "    aml_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_data_module_func = Module.load(ws, namespace='azureml', name='Join Data')\n",
    "execute_python_script_module_func = Module.load(ws, namespace='azureml', name='Execute Python Script')\n",
    "remove_duplicate_rows_module_func = Module.load(ws, namespace='azureml', name='Remove Duplicate Rows')\n",
    "split_data_module_func = Module.load(ws, namespace='azureml', name='Split Data')\n",
    "train_svd_recommender_module_func = Module.load(ws, namespace='azureml', name='Train SVD Recommender')\n",
    "select_columns_module_func = Module.load(ws, namespace='azureml', name='Select Columns in Dataset')\n",
    "score_svd_recommender_module_func = Module.load(ws, namespace='azureml', name='Score SVD Recommender')\n",
    "evaluate_recommender_module_func = Module.load(ws, namespace='azureml', name='Evaluate Recommender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_datastore = Datastore(ws, name=\"azureml_globaldatasets\")\n",
    "movie_ratings_data = Dataset.File.from_files(global_datastore.path('GenericCSV/Movie_Ratings')).as_named_input('Movie_Ratings')\n",
    "imdb_movie_titles_data = Dataset.File.from_files(global_datastore.path('GenericCSV/IMDB_Movie_Titles')).as_named_input('IMDB_Movie_Titles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name='sample_pipeline', description='Sample 10: Recommendation - Movie Rating Tweets',  default_compute_target='aml-compute')\n",
    "def sample_pipeline():\n",
    "    join_data = join_data_module_func(\n",
    "        dataset1=movie_ratings_data, \n",
    "        dataset2=imdb_movie_titles_data,\n",
    "        comma_separated_case_sensitive_names_of_join_key_columns_for_l = \"{\\\"isFilter\\\":true,\\\"rules\\\":[{\\\"exclude\\\":false,\\\"ruleType\\\":\\\"ColumnNames\\\",\\\"columns\\\":[\\\"MovieId\\\"]}]}\",\n",
    "        comma_separated_case_sensitive_names_of_join_key_columns_for_r = \"{\\\"isFilter\\\":true,\\\"rules\\\":[{\\\"exclude\\\":false,\\\"ruleType\\\":\\\"ColumnNames\\\",\\\"columns\\\":[\\\"Movie ID\\\"]}]}\",\n",
    "        match_case=\"True\",\n",
    "        join_type=\"Inner Join\",\n",
    "        keep_right_key_columns_in_joined_table=\"True\"\n",
    "    )\n",
    "    execute_python_script = execute_python_script_module_func(\n",
    "        dataset1=join_data.outputs.results_dataset,\n",
    "        python_script=\"\\n# The script MUST contain a function named azureml_main\\n# which is the entry point for this module.\\n\\n# imports up here can be used to\\n\\n# The entry point function can contain up to two input arguments:\\n#   Param<dataframe1>: a pandas.DataFrame\\n#   Param<dataframe2>: a pandas.DataFrame\\ndef azureml_main(dataframe1 = None, dataframe2 = None): return dataframe1[['UserId','Movie Name','Rating']],\"\n",
    "    )\n",
    "    remove_duplicate_rows = remove_duplicate_rows_module_func(\n",
    "        dataset=execute_python_script.outputs.result_dataset,\n",
    "        key_column_selection_filter_expression = \"{\\\"isFilter\\\":true,\\\"rules\\\":[{\\\"exclude\\\":false,\\\"ruleType\\\":\\\"ColumnNames\\\",\\\"columns\\\":[\\\"Movie Name\\\",\\\"UserId\\\"]}]}\",\n",
    "        retain_first_duplicate_row = \"True\"\n",
    "    )\n",
    "    split_data = split_data_module_func(\n",
    "        dataset=remove_duplicate_rows.outputs.results_dataset,\n",
    "        splitting_mode = \"Split Rows\",\n",
    "        fraction_of_rows_in_the_first_output_dataset=\"0.5\",\n",
    "        randomized_split=\"True\",\n",
    "        random_seed=\"0\",\n",
    "        stratified_split=\"False\",\n",
    "        stratification_key_column=\"\" # this should be optional\n",
    "    )\n",
    "    train_svd = train_svd_recommender_module_func(\n",
    "        training_dataset_of_user_item_rating_triples= split_data.outputs.results_dataset1,\n",
    "        number_of_factors=\"200\",\n",
    "        number_of_recommendation_algorithm_iterations=\"30\",\n",
    "        learning_rate=\"0.005\"\n",
    "    )\n",
    "    select_columns = select_columns_module_func(\n",
    "        dataset= split_data.outputs.results_dataset2,\n",
    "        select_columns= \"{\\\"isFilter\\\":true,\\\"rules\\\":[{\\\"exclude\\\":false,\\\"ruleType\\\":\\\"ColumnNames\\\",\\\"columns\\\":[\\\"UserId\\\",\\\"Movie Name\\\"]}]}\"\n",
    "    )\n",
    "    score_svd = score_svd_recommender_module_func(\n",
    "        trained_svd_recommendation= train_svd.outputs.trained_svd_recommendation,\n",
    "        dataset_to_score = select_columns.outputs.results_dataset,\n",
    "        recommender_prediction_kind = \"Rating Prediction\",\n",
    "        #Recommended_item_selection =\"\"\n",
    "        #Minimum_size_of_the_recommendation_pool_for_a_single_user=\"\",\n",
    "        #Maximum_number_of_items_to_recommend_to_a_user= \"\",\n",
    "        #Whether_to_return_the_predicted_ratings_of_the_items_along_with_the_labels= \"\"\n",
    "    )\n",
    "    evaluate = evaluate_recommender_module_func(\n",
    "        test_dataset=split_data.outputs.results_dataset2,\n",
    "        scored_dataset= score_svd.outputs.scored_dataset\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = sample_pipeline()\n",
    "pipeline.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = pipeline.submit(\n",
    "    experiment_name='sample_builtin_module', tags = {\"origin\": \"notebook\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft = pipeline.save(\n",
    "    experiment_name='sample_builtin_module'\n",
    ")\n",
    "#    default_compute_target='kubeflow-aks')\n",
    "draft"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "clwan"
   }
  ],
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python (aml1)",
   "language": "python",
   "name": "aml1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}